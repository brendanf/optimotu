---
title: |
  OptimOTU: Taxonomically aware OTU clustering  
  with optimized thresholds
author:
  - Brendan Furneaux^1^
  - Sten Anslan^1^
  - Panu Somervuo^2^
  - Jenni Hultman^2^
  - Nerea Abrego^1^
  - Tomas Roslin^3^
  - Otso Ovaskainen^1^
date: |
  ^1^Department of Biological and Environmental Science, University of Jyväskylä, Jyväskylä, Finland  
  ^2^Department of Panu and Jenni's affiliation, University of Helsinki, Helsinki, Finland  
  ^3^Department of Ecology, Swedish University of Agricultural Sciences, Uppsala, Sweden
output:
  bookdown::pdf_document2:
    toc: no
    number_sections: no
    keep_tex: yes
    latex_engine: xelatex
  bookdown::word_document2:
    toc: no
bibliography: all.bib
---

<!--   - Skylar^1^? -->
<!--   - Domenica^1^? -->
<!--   - Ilze^1^? -->
<!--   - Bess^2^ -->
<!--   - Dee^3^ -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, results = "asis")
```

# Abstract

OptimOTU is a taxonomically aware approach to OTU clustering.
It uses a set of taxonomically identified reference sequences to chose optimal genetic distance thresholds for grouping each ancestor taxon into clusters which most closely match its descendent taxa.
Then, query sequences are clustered according to preliminary taxonomic identifications and the optimized thresholds for their ancestor taxon.
The process follows the taxonomic hierarchy, resulting in a full taxonomic classification of all the query sequences into named taxonomic groups as well as placeholder "pseudotaxa" which accomodate the sequences that could not be classified to a named taxon at the corresponding rank.
OptimOTU is implemented as an R package, with computationally intensive steps implemented in C++ for speed, and incorporating open-source libraries for pairwise sequence alignment.
Distances may also be calculated externally, and may be read from a UNIX pipe, allowing clustering of large datasets where the full distance matrix would be inconveniently large to store in memory.
We also present the OptimOTU pipeline, a bioinformatics workflow for paired-end Illumina sequencing data that incorporates quality filtering, denoising, artifact removal, taxonomic classification, and OTU clustering with OptimOTU.
The OptimOTU pipeline is developed for use on high performance computing clusters, and scales to datasets with millions of reads per sample, and tens of thousands of samples.

# Introduction

Clustering of environmentally derived marker gene sequences into operational taxonomic units (OTUs) prior to downstream analysis is a common step in molecular ecology workflows.
The aim is to group sequences that are derived from the same species or strain, but differ due to errors during amplification or sequencing, or due to true genetic variation between gene copies in the same genome or between individuals.

Traditional agglomerative and greedy clustering algorithms treat these sources of variation in the same way, clustering sequences into OTUs based on a single global threshold [@dondoshansky2000blastclust; @li2006; @edgar2010; @mahe2015; @ratnasingham2013].
In this case the threshold should be chosen to be larger than typical error rates for the chosen sequencing workflow, and also larger than the intraspecies genetic variation present within the species of interest, while also being smaller than the level of genetic variation between species.

Alternatively, denoising algorithms such as Deblur [@amir2017], DADA2 [@callahan2016], and UNOISE2 [@edgar2016] incorporate sequence abundance information to attempt to separate true biological variation from sequencing errors, yielding clusters known variably as amplicon sequence variants (ASVs), exact sequence variants (ESVs), or zero-diameter OTUS (zOTUs).
Denoising may successfully recover true biological variation even below the sequencing error rate, but as a result also frequently separate sequences that are derived from the same species or strain, and so ASVs may be subjected to a second clustering step to group sequences using a biologically motivated threshold.
In either case, it is common to choose a single threshold, often 97% similarity, for all sequences,
even in studies that target large and diverse taxonomic groups such as all fungi, all eukaryotes, or all prokaryotes.
However, levels of genetic variation within species are known to vary between taxonomic groups as well as between marker genes, so these thresholds may result in over- or under-clustering, and most often both within the same dataset.

Here we present OptimOTU, a taxonomically aware approach to OTU clustering, in which optimized thresholds are used for different taxonomic groups.

# Implementation

The OptimOTU algorithm has three phases: threshold optimization, preliminary taxonomic identification, and clustering.
Threshold optimization is usually the most computationally intensive step, but it does not need to be repeated for every study in a set of optimized thresholds for the taxonomic groups of interest has already been determined.

Threshold optimization is performed by the function `optimize_thresholds()`, which takes as input a set of reference sequences and their taxonomic identifications.
These can be obtained from a curated global database such as BOLD [@ratnasingham2013], UNITE [@abarenkov2010], or PR2 [@guillou2013], or from a local database of sequences that have been taxonomically identified by experts.
It is also possible to use a subset of the sequences from the study in question that have been identified with high confidence by algorithms such as the RDP naive Bayesian classifier [@wang2007], SINTAX [@edgar2016a], PROTAX [@somervuo2016; @abarenkov2018a; @roslin2022], or similar methods.
This was the approach used by @ovaskainen2024.
These sequences are then clustered by single-linkage hierarchical agglomerative clustering, resulting in a tree structure which can be cut at any level to produce a partition of the reference sequences into clusters.
Such partitions are calculated for a range of test thresholds, for example 0.0 to 0.4 in steps of 0.001, and the resulting clusters are compared to the taxonomic identifications to determine the threshold that produces clusters that most closely match the taxonomy at each rank.
This process is conceptually repeated for each taxon in the reference set, and  which has enough representative sequences (default: 10) and enough descendant taxa (default: 5) to be informative.
In practice, clustering is performed concurrently for all relevant taxa, with only a single pass through the sequences.

```{r threshold_optimization, child="cluster_optimization_figure.Rmd"}

```

Once the optimized thresholds have been determined, they can be used to cluster query sequences.
OptimOTU inverts the typical workflow in which sequences are clustered first and then taxonomically identified, and instead uses preliminary taxonomic identification first, followed by clustering informed by the identifications.
The taxonomic identification can be performed by any method with a stopping condition, meaning that taxonomic identification is truncated to higher ranks if the confidence is low.
This includes any of the wide range of algorithms which produces confidence scores for classifications at each rank, such as the popular k-mer profile naive Bayesian classifier first implemented by the RDP classifier [@wang2007] but also available in software such as Mothur [@schloss2009a], QIIME 2 [@bokulich2018] and DADA2 [@callahan2016], as well as SINTAX [@edgar2016a], PROTAX [@somervuo2016; @abarenkov2018a; @roslin2022], IDTAXA [@murali2018], Gappa [@czech2020], BayesANT [@zito2023], and MycoAI [@romeijn2024].
Additionally, algorithms based on last common ancestor (LCA) consensus such as implemented in CREST [@lanzen2012], USEARCH, [@edgar2010], VSEARCH [@rognes2016], and QIIME 2 [@bokulich2018] may be suitable.

The clustering process is then performed using the `optimotu()` function, which proceeds in a hierarchical manner through the taxonomic ranks, starting with the rank below the root.
Within each rank, the sequences are grouped by their cluster identity at the rank above and processed separately (Fig \@ref(fig:clustering)).
At each rank, the clustering proceeds in three stages.
First, cluster cores are formed by grouping sequences which have the same taxonomic identifications at the current rank.
Second, sequences which were not identified at the current rank are assigned to cluster cores by closed-reference clustering, using the optimized threshold for the closest enclosing taxon for which a threshold was determined.
The closed-reference clustering is performed by pairwise comparisons between the unassigned sequences and all sequences in the cluster cores, and if the distance is less than the threshold, the sequence is added to the cluster.
If the sequence is closer than the threshold to sequences from multiple cluster cores, then it is assigned to the one with the closest match.
If there is a tie between multiple sequences in different cluster cores, then the new sequence is assigned to the cluster core of one of the tied sequences at random.
The closed reference clustering phase is performed iteratively, with the sequences newly assigned to cluster cores in the previous iteration being used as the target sequences in the next iteration, until no new matches are found.
In this way, the resulting partition approximates single-linkage clustering, although clusters which would be joined in full single-linkage may be separated if they contain sequences with different taxonomic identifications.
In the third and final step, sequences which are still unassigned at the chosen rank are *de novo* single-linkage clustered with the optimized threshold.
The clusters from the *de novo* clustering are given placeholder taxonomic names of the form "pseudo{rank}_{number}", where {rank} is the rank of the cluster and {number} is a unique integer identifier.

(ref:clustering) OptimOTU clustering procedure.
The same procedure is used at all ranks, but here is illustrated at the species level.
In this constructed example, ASVs belonging to family F have already been clustered into two named genera G1 and G2 and one pseudogenus pG3 during previous iterations.
Clustering thresholds are depicted as circular boundaries around ASVs, such that when the circles overlap, the ASVs are more similar than the threshold.
In this example, an optimized species-level clustering threshold has been determined for G1 based on reference data, but not for G2.
Thus, ASVs in G2 are clustered using a species-level threshold inherited from F.
Because it is not possible to optimize clustering within a pseudotaxon, ASVs in pG3 are also clustered using the threshold inherited from F.
In the first stage, cluster cores are formed from ASVs which have been identified to species (colored dots), regardless of genetic distance.
Thus the ASVs belonging to species s2 and s3 are not linked, despite being within the species-level threshold, while all three ASVs belonging to species s5 are linked, despite one of them being outside the species-level threshold from either of the others.
Next, closed-reference clustering links unidentified ASVs (gray dots) to the nearest cluster core if they are within the species-level threshold.
Note that this does not allow the merger species s1 with s2 or s3, despite the presence of an ASV which is within the threshold of all three cluster cores; it is only allowed to merge with the closest cluster core.
The closed-reference clustering step is iterated as long as new matches are found, allowing an additional ASV to be linked to species s5.
Finally, ASVs which have not been linked to any cluster core are *de novo* clustered, forming pseudospecies ps4, ps6, ps7, and ps8.

```{tikz clustering, fig.cap="(ref:clustering)", code=readLines("clustering_figure.tex")}
```


When the clustering is complete, the result is a full taxonomic classification for each sequence, including named taxa and pseudotaxa.
Clusters at the lowest rank, typically species, are then used as OTUs for further analysis.

## Pairwise distance calculation algorithms

OptimOTU can be used with various methods for calculating pairwise distances between sequences.
Three methods are implemented internally in the R package and can be selected using the option `dist_config` to `optimize_thresholds()` or `optimotu()`.

The first method is a simple Hamming distance, which counts the number of differences between two sequences.
Although this is by far the fastest method, it is only suitable if both the query and reference sequences are already globally aligned.
This is the recommended method for use with protein-coding sequences such as COI, and may also be applied to the ribosomal small subunit (SSU/12S/16S/18S) 5.8S, and large subunit (16S/23S/25S/26S/28S) RNA, but should not be used for sequences containing introns, spacers such as ITS, or other regions where multiple alignment across broad taxonomic ranges is not reliable.
The implementation is adapted from ProtaxA [@roslin2022] which uses a 4-bit one-hot encoding of DNA sequences and the bit-count instruction of modern processors to accelerate the calculation.
It is activated using `dist_config = dist_hamming(min_overlap, ignore_gaps)`.
The two options control handling of gap characters.
The `min_overlap` defines a minimum number of sites which contain a nucleotide in both sequences being compared.
Although low pairwise alignment overlap is expected to be rare in a global multiple sequence alignment of genuine metabarcoding reads of "alignable" markers such as 16S or COI, which should consist of full-length reads of the homologous region between two primers, it may occur in the case of artefactual sequences, and may also be more common in reference databases, where sequences  may come from different primer sets or have been trimmed to different lengths.
The `ignore_gaps` option allows the user to specify whether sites where a gap in one sequence is aligned to a nucleotide in the other sequence should be ignored in the distance calculation or counted as a mismatch.
End gaps and gap-gap sites are always ignored.

The second method uses the open-source C++ library Edlib [@sosic2017] to calculate edit (Levenshtein) distance between two sequences using Needleman-Wunsch dynamic programming.
Edlib also allows the use of banding to limit the search space, and early stopping when the alignment score exceeds a predefined threshold.
This is the fastest internal method for calculating distances between unaligned sequences when the distances are large.
However, the pairwise alignments may not be as biologically relevant as those using more complex gap-affine scoring schemes.
The Edlib method is activated using `dist_config = dist_edlib()`.

The third method uses wavefront alignment (WFA) with the open-source C++ library WFA2 [@marco-sola2021].
WFA is especially efficient for very similar sequences, and in addition to the edit distance, can also calculate gap-linear, gap-affine, and dual-cost gap-affine alignments.
Note, however, that although the alignment may be calculated with various scoring functions, the distance used by OptimOTU is always the edit distance (not including end gaps) divided by the alignment length, as used by, e.g., USEARCH [@edgar2010].
Like Edlib, WFA2 support banding and early stopping.
It is activated by setting `dist_config = dist_wfa2(match, mismatch, gap_open, gap_extend, gap_open2, gap_extend2)`, where the arguments are the scores for the dual-cost gap-affine scoring function.
When the supplied scores are equivalent to a simpler scoring function (as in the default case, which is edit distance) the alignment is calculated using that simpler function.
WFA2 in edit-distance mode is the default for OptimOTU.

Finally, in the fourth method, distances are calculated externally and
supplied as a distance matrix in three-column (query, reference, distance) format, which can be read from a file or UNIX pipe, allowing the use of arbitrary external tools.


Alternatively, distances can be supplied as a distance matrix in three-column (query, reference, distance) format, which can be read from a
file or UNIX pipe, allowing the use of arbitrary external tools.
The R package has a function which runs USEARCH [@edgar2010] to calculate sparse distance matrices via the `calc_distmx` function for the optimization and *de novo* clustering stages, and `usearch_global` for the closed-reference clustering stage.

## Clustering algorithms

OptimOTU implements several single-linkage clustering algorithms, of which SLINK and a novel tree-based algorithm are recommended for use.

The SLINK algorithm [@sibson1973], which operates at the theoretically optimal complexities of $O(n^2)$ time and $O(n)$ space, where $n$ is the number of sequences.
Unfortunately, SLINK is an inherently serial algorithm, and must process the distances in a predefined order, so it is not possible to trivially parallelize [but see @nolet2023].
The OptimOTU implementation of SLINK allows clustering of an incomplete distance matrix, provided the elements which are present are in the correct order, by proceeding as if the missing elements were at infinite distance.
It also allows calculation, before each new pairwise distance is processed, of the maximum distance which would need to be obtained in order to cause an update.
This is used to adaptively set the band width and maximum alignment score for Edlib and WFA2, in order to reduce the number of unnecessary calculations.
The SLINK algorithm can be activated using the option `clust_config = clust_slink()` to `optimize_thresholds()` or `optimotu()`.

The tree-based algorithm maintains a full hierarchical clustering tree at all stages of clustering, which is updated as each new pairwise distance is processed.
Although this algorithm has a higher time complexity than SLINK, it can process the distances in any order.
Like SLINK, the tree-based algorithm can calculate the maximum relevant distance for a given sequence pair, and use this to set the band width and maximum alignment score for Edlib or WFA2.
Because it is compatible with out-of-order distance matrices, the tree-based algorithm is the default clustering algorithm in OptimOTU, but it can be activated or configured using the option `clust_config = clust_tree()` to `optimize_thresholds()` or `optimotu()`.

The two clustering algorithms should always produce identical partitions when run on the same distances.
The test suite for OptimOTU tests the clustering algorithms with all applicable parallelization options for consistency with each other and the base R `hclust()` command.
Additionally, internal consistency checks can be activated by setting the optional argument `test = 1` or `test = 2` in `clust_tree()`.
These checks are computationally expensive, and so are not recommended for routine use, but can be useful if you believe you have found a bug in the tree-based algorithm.

## Parallelization

There are three available parallelization options, which are configured by setting the `parallel_config` argument in `optimize_thresholds()` or `optimotu()`.

The first method relies on the ability of the tree-based algorithm to process pairwise distances in any order, and to calculate the maximum relevant distance for a given pair before processing it.
Because the majority of pairwise distances do not in practice trigger updates, multiple parallel threads can cluster (and calculate distances) using two-stage locking, in which the tree is non-exclusively locked for reading to calculate the maximum relevant distance for a given pair, and then only exclusively locked for writing when a relevant distance is found.
This is referred to as the "concurrent" option, selected using `parallel_config = parallel_concurrent(threads)`, where `threads` is the number of parallel threads to use for updating the tree.

It is also possible to merge two trees using only $O(n)$ updates, which allows an alternate parallelization technique, where multiple tree structures are processed in parallel and then merged at the end.
This technique can also be used to cluster different subsets of the distance matrix in parallel using SLINK, and then merge the results using the tree-based algorithm.
This method is referred to as the "merge" option, accessed by setting the option `parallel_config = parallel_merge(threads)`, where `threads` is the number of tree structures, each updated by its own thread.
This is the only parallelization algorithm which can be used with SLINK if `threads` $> 1$.

Finally, the two parallelization techniques can be combined, with multiple tree structures each updated by multiple parallel threads, and then merged at the end.
This is referred to as the "hierarchical" option, accessed by setting the option `parallel_config = parallel_hierarchical(threads, shards)`, where `threads` is the total number of threads and `shards` is the number of tree structures.

## Measures of clustering quality

OptimOTU calculates several measures to compare the quality of a clustering partition relative to a reference taxonomy.
The first group of these are based on pair counting, whereby deciding whether each pair of sequences belong to the same cluster is treated as a binary classification problem.
Thus, a $2\times2$ confusion matrix can be constructed, whereby if the sequence pair is grouped together in both the reference taxonomy and in the clustering partition, it is a true positive (TP), if they are in different clusters in both, it is a true negative (TN), if they are in the same cluster in the reference but different clusters in the partition, it is a false negative (FN), and if they are in different clusters in the reference but the same cluster in the partition, it is a false positive (FP).
Various measures can be calculated from the confusion matrix, of which the Rand index [RI\; @rand1971], adjusted Rand index [ARI\; @hubert1985], Fowlkes-Mallows index [FMI\; @fowlkes1983], and Matthews correlation coefficient [MCC\; @matthews1975] are implemented in OptimOTU.
Of these, the RI is not corrected for chance, so it tends to give higher scores to small clustering thresholds, i.e., clusterings with many small clusters, so it is not recommended.
Because the calculation of the confusion matrix is the most computationally expensive part of calculating these measures, it is more efficient to calculate the confusion matrix once and then calculate multiple measures from it if multiple measures are desired, and this is supported in OptimOTU by the function `confusion_matrix()`,
which is parallelized, and a function for each index which takes the confusion matrix as input.


The second group of measures are based in information theory, and include the mutual information [MI\; @strehl2002] and adjusted mutual information [AMI\; @vinh2010].
These measures consider the cross-entropy between clusters in the test partition and the reference taxonomy.
Because the MI is not corrected for chance and has no consistent upper bound, it is recommended to always use AMI if an information theoretic measure is desired.

The third group is set-matching measures, where a single measure, the weighted multiclass F-measure [FM\; @steinbach2000], is implemented.
Unlike the previous measures, the FM considers only the best-matching cluster for each taxon in the reference taxonomy, so it is not sensitive to the number or makeup of any "extra" clusters in the test partition.



## The OptimOTU pipeline

The OptimOTU pipeline is a full bioinformatics pipeline built around the OptimOTU clustering algorithm.
It is used to process demultipexed paired-end reads into a species x sample occurrence matrix and taxonomy for each OTU.
The pipeline is implemented using the `targets` workflow management package [@landau2021], and is designed to be run on high-performance computing clusters for very large metabarcoding projects.
However, it can also be run on a laptop or desktop computer for smaller projects.
The use of `targets` allows the pipeline to skip already completed steps when re-run, which is useful both for debugging, and for "on-line" processing of new samples as they are sequenced.
An alternate implementation of the same processing steps in the PipeCraft 2 graphical interface [@anslan2017, https://pipecraft2-manual.rtfd.io] is in progress.

In brief, the workflow consists of primer removal, read quality filtering, denoising, removal of tag-switches, *de novo* and reference-based chimera removal, probabilistic taxonomic assignment, and finally taxonomically-guided hierarchical clustering.
There are also a number of optional steps which may only be relevant for certain marker genes, taxonomic groups, or laboratory workflows.
These include detection of artificial "spike-in" sequences, detecting and removing outgroup sequences, alignment to a profile hidden Markov model (HMM) or covariance model (CM), detection of nuclear mitochondrial pseudogenes (NuMts), or assignment of sequences to ecological guilds or functional groups.
Configuration of these optional steps, as well as settings for the standard steps, is performed using a human-readable YAML configuration file.

The pipeline is organized broadly into three phases, which are distinguished by the unit of parallelization (Fig \@ref(fig:pipeline-overview)).
In the first phase, most operations are performed on individual samples, although some steps share information between all samples within a sequencing run, and all steps are performed in batches of no more than 96 samples.
This phase ends with the production of a master list of candidate ASVs and a table of read counts for each candidate ASV in each sample.
In the second stage, operations are performed on the master list of condidate ASVs, which is split into batches for parallel processing.
Operations at this stage primarily consist of various methods to filter the ASVs to remove artifacts, producing a final ASV list, as well as preliminary taxonomic identification.
In the third phase, the final ASV list is clustered into OTUs using the OptimOTU algorithm.
After the main processing steps are complete, optional post-processing steps may be performed, and the results are written to disk as a set of tables in TSV and RDS formats and sequences in gzipped FASTA format, as well as a zip archive containing the output files, and named according to the date of the run.

```{tikz pipeline-overview, fig.cap="Overview of the OptimOTU pipeline. (placeholder)"}
\usetikzlibrary{positioning, shapes}
\begin{tikzpicture}
  \node[draw, ellipse, minimum width=3cm, minimum height=1cm] (input) {Input reads};
  \node[draw, rectangle, minimum width=3cm, minimum height=1cm, below=of input, align=center] (phase1) {Phase 1:\\quality filtering,\\denoising};
  \node[draw, ellipse, minimum width=3cm, minimum height=1cm, below=of phase1] (asvs1) {Candidate ASVs};
  
  \node[draw, rectangle, minimum width=3cm, minimum height=1cm, below=of asvs1, align=center] (phase2) {Phase 2:\\artifact removal,\\taxonomic assignment};
  \node[draw, ellipse, minimum width=3cm, minimum height=1cm, below=of phase2] (asvs2) {Final ASVs};
  \node[draw, rectangle, minimum width=3cm, minimum height=1cm, below=of asvs2, align=center] (phase3) {Phase 3:\\OptimOTU clustering};
  \node[draw, ellipse,minimum width=3cm, minimum height=1cm, below=of phase3] (output) {Output OTUs};
  \draw[->] (input) -- (phase1);
  \draw[->] (phase1) -- (asvs1);
  \draw[->] (asvs1) -- (phase2);
  \draw[->] (phase2) -- (asvs2);
  \draw[->] (asvs2) -- (phase3);
  \draw[->] (phase3) -- (output);
\end{tikzpicture}
```

Although many of the steps in the pipeline are performed in R using various freely available packages, several external command-line software tools are also used.
The R version, R packages, and external tools are enumerated along with recommended version numbers in an included Conda environment file [@conda_contributors_conda_A_system-level] which can be used to install the dependencies automatically, or can be read by the user to install the required software manually.

### Input files

The primary input to the pipeline is a set of paired-end FASTQ files, one for each sample.
Gzipped files are supported.
In the simplest cases, the sample names and read pairings are encoded in the file names, and can be automatically inferred by the pipeline.
In these cases, the reads should be placed in a directory structure within `sequences/01_raw/` in the project directory, with each sequencing run in a separate subdirectory.
Additional levels of directory structure or non-FASTQ files are ignored.

Alternatively, the sample names, sequencing run identifiers, and file paths, as well as additional sample-specific information, can be specified in a TSV file, which is typically placed in a `metadata/` directory in the project directory, and is specified in the configuration file with the option `custom_sample_table`.
This option may be useful if the project is set up to use raw reads from a public repository such as the Sequence Read Archive (SRA) or European Nucleotide Archive (ENA).

### Orientation, primer detection and quality filtering

The OptimOTU pipeline can process reads with a variety of orientations, depending on the indexing scheme used in the sequencing run and specified in the configuration file with the option `orient`.
Possible values are "fwd", "rev", "mixed", and "custom".
In the "fwd" orientation, the forward primer is expected at the 5' end of R1 and the reverse primer at the 5' end of R2.
In the "rev" orientation, the reverse primer is expected at the 5' end of R1 and the forward primer at the 5' end of R2, and the ASV sequence is reverse-complemented after denoising and merging of each pair.
In the "mixed" orientation, both orientations are expected and searched for in every sample. Reads detected in the "fwd" and "rev" orientation are processed separately through phase 1 of the pipeline until pair merging, at which point the reverse-oriented reads are reverse-complemented.
In the "custom" orientation, the user must supply a custom sample table (see above) which includes a column "orient" with values "fwd", "rev", or "mixed" for each sample.
This is primarily used for certain indexing schemes where different samples are sequences in different orientations to increase the sequence diversity of the reads, which may improve basecalling accuracy [reference here].

Primers are specified in the configuration file with the options `forward_primer` and `reverse_primer`.
The expected primer at the 5' end of each read is searched for using Cutadapt [@martin2011].
Read pairs where the expected primer is not found are discarded.
The reverse-complemented sequence of the other primer is also searched for at the 3' end of each read, which may occur in marker sequences with highly variable length such as ITS, and removed if found, but its presence is not required.
Settings for Cutadapt are specified in the configuration with sub-options to `trimming`.
In particular, the action to take on the primer sequence is specified with the option `action`; although Cutadapt has several options for this, the OptimOTU pipeline supports two, "trim" and "retain".
Option "trim" removes the primer sequence from the read immediately, while "retain" leaves it in place, but trims any bases before the primer sequence.
If option "retain" is used, the trimming still occurs, but not until the assembly of the master ASV list at the end of phase 1.
This means that the primer sequence is present during the denoising stage.
The conserved endpoints may aid in pairwise alignment of highly variable sequences during denoising.
However, this option is not recommended in most situations, and in particular is not suitable when primers with degenerate bases are used.

At the same time as primer searching, reads are trimmed and quality filtered.
Options are user configurable, but a typical set of options would trim low quality based from the 5' and 3' ends of each read, remove reads with any ambiguous bases after trimming, and discard reads which are less than a specified length.
Options controlling primer matching, trimming, and filtering can optionally be included in the custom sample table, which is useful when different sequencing runs have been sequenced with different settings or instruments.

### Denoising

The denoising steps are performed using the DADA2 package [@callahan2016].
Trimmed read pairs are first subjected to an additional round of quality filtering using DADA2's `fastqPairedFilter()`, based on the expected number of errors in the read.
Error profiles are then learned separately for each sequencing run, read, and orientation using the `learnErrors()` function.
Sequences with binned quality scores, as produced by newer Illumina sequencers, are automatically detected, and the error model is adjusted accordingly.
Denoising is then performed using the `dada()` function, and read pairs are merged using the `mergePairs()` function.
The denoised R1 and R2 reads from any reverse-oriented read pairs are swapped at this stage, so that the merged, denoised ASVs are all in the same orientation.

### ASV table construction

Due to the very large number of samples and high diversity of ASVs, the standard DADA2 function to combine denoised sequences from multiple samples to form a matrix had prohibitively high memory requirements. We instead formed a list of all unique ASVs by first finding unique ASVs in each sample, then in each sequencing run, and then finally across the entire data set. These sequences were then stored in a single compressed fasta file, which we indexed with FastqIndEx version 0.9.0b (https://github.com/DKFZ-ODCF/FastqIndEx/releases/tag/0.9.0b) for fast extraction of contiguous subsets. The matrix of ASV read counts in each sample was then constructed and stored in coordinate list (COO) sparse matrix format, as a three column R data frame where the columns represent a sample identifier, index of the sequence in the master ASV file, and number of reads. Potential cases of tag-switching were detected and removed using an R implementation of the UNCROSS2 algorithm56, using a threshold uncross score of f=0.01. Because different sequencing runs were processed and sequenced independently, UNCROSS2 was applied only within sequencing runs.
A number of operations were then performed on the ASVs, including de novo and reference-based chimera detection, scoring and aligning to a hidden markov model, removal of potential nuclear-mitochondrial pseudogenes, flagging potential non-animal sequences, and taxonomic assignment. These steps, most of which flag some ASVs for removal, could in principle be performed in stages, thereby reducing the computational load of later stages – because only sequences which passed all previous stages would then need to be considered. We instead performed them in parallel, so that it is possible to compare the results of different stages. As such comparisons are not relevant to CORAL, we do not present them here.

### Reference sequences and taxonomy

Reference sequences and taxonomy were retrieved from BOLD52. The taxonomic hierarchy on BOLD is a consolidation of numerous online databases and taxonomic publications. The hierarchy is constantly updated through both user submissions of new taxon names and the incorporation of new taxon-specific checklists. Some of the key data sources are listed on the Taxonomic Resources page on BOLD (https://boldsystems.org/index.php/resources/taxresource). The version of the hierarchy used in this study was retrieved from BOLD on April 21, 2022. Two BOLD data packages were utilized in this study. A 7M reference barcode set, used for training the Protax taxonomic classifier (see below), consisted of all COI data publicly available on BOLD as of June 1, 2022. Any sequences flagged due to data quality issues, such as reading frame shifts, or suspected cross-contamination or misidentification, as well as non-animal sequences, were excluded from this reference dataset. An additional 8.7M barcode data set, in which non-animal sequences were retained for use in chimera detection and flagging non-animal sequences (see below), was downloaded Feb 9, 2024 (https://www.boldsystems.org/index.php/datapackage?id=BOLD_Public.09-Feb-2024). The majority of sequences in both datasets originate from research programs led by the International Barcode of Life (iBOL) Consortium and the Centre for Biodiversity Genomics, University of Guelph, such as the Global Malaise Trap Program (https://biodiversitygenomics.net/projects/gmp/) and BIOSCAN (https://biodiversitygenomics.net/research/bioscan/). 

### Chimera detection

 De novo chimera detection was performed using a partial re-implementation of the consensus method of DADA2 in order to operate on the sparse matrix representation. The internal DADA2 function C_table_bimera2 was used to flag potential bimeras in small subsets of sequences, and the results were combined into a master list. Each ASV which was flagged as a potential bimera in at least 90% - 1 of the samples it occurred in was removed.
Reference-based chimera detection was performed using the UCHIME algorithm50 as implemented in VSEARCH (--uchime_ref), using as reference the 8.7M barcode dataset described above.

### HMM alignment and NuMt detection

Both the ASV sequences and the 7M and 8.7M barcode reference sets were aligned to the nucleotide hidden Markov model (HMM) of the COI barcode region from57 using the hmmalign command of HMMER version 3.3.258. Extra nucleotides at the beginning and end of the aligned region were removed (--trim). Insertions, represented by HMMER as lower-case characters in the aligned sequences, were removed from the reference data sets, but retained at this stage in the ASV sequences. ASV sequences with frame shift mutations (insertions or deletions with length not divisible by 3) or in-frame TAG/TAA stop codons were discarded as potential nuclear mitochondrial pseudogenes (NuMts)38. Additionally, the ASV sequences were scored against the same HMM with the nhmmer command, also from HMMER 3.3.2. ASVs which did not match the model from at least position 245 to 652, corresponding to the BF3-BR2 amplicon with a few bases truncated at each end, or for which the calculated match score was less than 200, were regarded as likely sequencing artifacts and discarded.

### Taxonomic placement

Taxonomic placement of animal sequences was conducted with the Protax classifier59 using parameterization similar to the one used in60 and trained on the 7M barcode reference set. During classification, the nucleotides were represented as 64-bit integers in order to gain speedup when computing pairwise distances. Each nucleotide was converted into a 4-bit vector (A: '1000', C: '0100', G: '0010', T: '0001', N: '0000') so that 16 consecutive nucleotides could be represented in one 64-bit integer. The number of matching nucleotides along the alignment could then be calculated efficiently by using a fast built-in function 'popcountl' in C. The number of taxa after adding unknown branches (one outside-of-known-taxonomy node under each parent node) was 37, 157, 882, 7963, 18676, 25832, 102736, and 572097 in phylum, class, order, family, subfamily, tribe, genus, and species level, respectively. There were 7279191 reference sequences whose annotations reached 99% family level, 69% subfamily level, 64% genus level, and 42% species level. The number of taxonomy nodes with at least one reference sequence was 29 at the phylum level, 103 at the class level, 605 at the order level, 4909 at the family level, 7580 at the subfamily level, 9161 at the tribe level, 50659 at the genus level, and 199841 at the species level.
The same pairwise distance algorithm was also used to find the single closest match for each ASV in the 8.7M barcode reference set. Sequences whose closest match was to a non-animal sequence were flagged but retained until after the clustering step.

### Taxonomically guided clustering

Due to frequent intra-species variation in the COI gene59, ASVs are not a reliable proxy for unique species. We therefore performed a multi-stage hierarchical clustering of the ASV sequences, taking into account the results of taxonomic classifications from Protax. Clustering was performed first at the phylum level, then proceeded through the taxonomic ranks until the final round resulted in approximately species-level OTUs, which were used as the main unit of analysis for CORAL. At each rank, clustering proceeded in three stages: core formation, closed-reference clustering, and de-novo clustering. In the core formation stage, ASVs which were identified at the current taxonomic rank with at least 90% confidence by Protax were grouped according to their taxonomic identifications. In the closed-reference clustering stage, ASVs which could not be identified with 90% confidence were joined to cluster cores if the pairwise sequence dissimilarity, calculated by the Protax algorithm, between the ASV and a member of the cluster core was less than a rank-specific threshold of 0.12 for phylum, 0.10 for class, 0.07 for order, 0.05 for family, 0.04 for subfamily, 0.035 for tribe, 0.03 for genus, and 0.02 for species. If an ASV matched more than one cluster core at below the given threshold, it was joined only to the one which it matched most closely, so that cluster cores were never merged. This stage was repeated, checking for matches between unclustered ASVs and newly clustered sequences, until no new matches were found. Finally, in the de novo clustering stage, remaining unclustered OTUs were single-linkage clustered, with the same rank-specific dissimilarity thresholds. Placeholder “pseudotaxon” names at each rank were given to the de novo clusters, such that the final OTUs were placed in a full taxonomic hierarchy consisting of both known taxa and potentially novel taxa. Finally, all ASVs in pseudophyla (i.e., de novo clusters at phylum rank) which contained a large number of ASVs which were flagged as non-animal (see above) were removed.

### Implementation and execution

The OptimOTU pipeline is implemented using the targets 1.5.1 workflow management package60, here executed using the crew 0.9.061 and crew.cluster 0.3.062 backends in R 4.2.363 on the Puhti cluster at CSC – IT Center For Science, Finland.


, which is also used to generate barcode identification numbers (BINs) in the BOLD database [@ratnasingham2013] and species hypotheses in the UNITE database [@abarenkov2010].

# Results

# Discussion

OptimOTU uses a modified version of single-linkage (also known as minimum-distance or nearest-neighbor) clustering at all ranks.
In single linkage clustering, all pairs of sequences which are separated by a genetic distance less than the chosen threshold are grouped together.
Thus, the threshold may be considered as the minimum genetic distance between distinct OTUs.
This is in contrast to complete-linkage clustering, in which the threshold defines the maximum distance between any two sequences within the same OTU, and
various intermediate-linkage methods, such as average-linkage, as well as centroid-based clustering methods, in which the threshold defines the maximum distance between a sequence and the centroid of its OTU (Fig \@ref(fig:clustering)).
Researchers have worried about the so-called "chaining" effect of single linkage clustering, in which a single sequence may link two otherwise distinct OTUs, and refer to single-linkage clusters as being "amoeboid" rather than "circular".
This effect can be clearly seen in Fig \@ref(fig:clustering) and similar examples of clustering in two dimensions, it is important to note that genetic distances between sequences exist in an extremely high-dimensional space, but also one in which the available distance to travel on a each "dimension" (i.e., the nucleotide at a single position) is very small.
Furthermore, while independent random sequencing errors may be supposed to densely populate the space around a true biological sequence, implying clusters which are "circular" in the sense that the included sequences are all within a given range of the centroid, genetic variants within and between species are
derived through a branching process through time from a common ancestor, which cannot be assumed to be present in the data or even extant.

A major advantage of single linkage clustering is that the clustering criterion uniquely defines the result, and so the process is deterministic
and not dependent on the order of the input sequences.
This is in contrast to complete- and average-linkage clustering, as well as centroid-based methods, where multiple possible clusterings fitting the criteria may exist.

# Conclusions

# Funding {.unnumbered}

This work was supported by the Academy of Finland [grant number Otso's Academy professor]; and the European Research council [grant number BGE].

# Acknowledgements {.unnumbered}

The authors would like to thank various people. Computational resources were provided by CSC – IT Center For Science, Finland.
